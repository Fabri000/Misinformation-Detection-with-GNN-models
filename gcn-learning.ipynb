{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Inport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.utils.convert import from_networkx,to_networkx\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn.models import GIN,GCN\n",
    "from torch_geometric.explain.metric import groundtruth_metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classi ausiliarie di utilit√†\n",
    "Classe che permette di estrarre i grafi salvati su file e rappresentarli in formato Data in manniera opportuna, oltre a permettere di estrarre le maschere per training e test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCreator():\n",
    "\n",
    "    def __init__(self,paths,node_attrs,edge_attrs,label):\n",
    "        '''\n",
    "        Args:\n",
    "            paths (list[str]): Paths ai file contenenti i grafi\n",
    "            node_attrs (list[str]): Attributi dei nodi\n",
    "            edge_attrs (list[str]): Attributi degli archi\n",
    "            label (str): Etichette ground truth\n",
    "        '''\n",
    "        self.node_attrs=node_attrs\n",
    "        self.edge_attrs=edge_attrs\n",
    "        self.label=label\n",
    "        self.data=self._read_from_json_(paths)\n",
    "        self._set_masks_()\n",
    "    \n",
    "    def _read_from_json_(self,paths):\n",
    "        '''\n",
    "        Estrai i grafi contenuti in una lista di file.\n",
    "        Args:\n",
    "            paths (list[str]): Paths ai file contenenti i grafi\n",
    "        Returns:\n",
    "            GS (list[Data]): Grafi contenuti nei files\n",
    "        '''\n",
    "        GS = []\n",
    "        for path in paths:\n",
    "            json_gs= None\n",
    "            with open(path,'r') as file:\n",
    "                json_gs = json.load(file)\n",
    "                file.close()\n",
    "            for g in json_gs:\n",
    "                GS.append(json_graph.node_link_graph(g))\n",
    "        return self._prepair_data_(GS)\n",
    "    \n",
    "    def _prepair_data_(self,GS):\n",
    "        '''\n",
    "        Trasforma i grafi in formato pytorch_geometric andando a specificare le feature dei nodi,\n",
    "        degli archi e le etichette ground truth.\n",
    "        Args:\n",
    "            GS (list[Graph]): Grafi formato Networkx\n",
    "        Returns:\n",
    "            datas (list[Data]): Grafi in formato Data pytorch_geometric\n",
    "        '''\n",
    "        datas = []\n",
    "        for g in GS:\n",
    "            tmp = from_networkx(g,group_node_attrs=self.node_attrs)\n",
    "            tmp.y = tmp[self.label]\n",
    "            tmp[self.label] = None\n",
    "            self._normalize_features_(tmp)\n",
    "            datas.append(tmp)\n",
    "        return datas\n",
    "    \n",
    "    def _normalize_features_(self,G):\n",
    "        '''\n",
    "        Normalizza le feature di un grafo in un range [0,1]\n",
    "        Args:\n",
    "            G (grafo)\n",
    "        '''\n",
    "        x = G.x\n",
    "        min_vals = x.min(dim=0, keepdim=True).values\n",
    "        max_vals = x.max(dim=0, keepdim=True).values\n",
    "        G.x = (x - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    def _set_masks_alt_(self,train_ratio=0.7): #problema qui sulla selezione delle maschere\n",
    "        '''\n",
    "        Assegna le maschere per i nodi associati al training set e al test set\n",
    "        Args:\n",
    "            train_ratio (float): frazione dei nodi da incorporare nel training set\n",
    "        '''\n",
    "        for g in self.data:\n",
    "            num_nodes = g.x.shape[0]\n",
    "            num_train = int(num_nodes * train_ratio)\n",
    "            idx = [i for i in range(num_nodes)]\n",
    "\n",
    "            np.random.shuffle(idx)\n",
    "            train_mask = torch.full_like(g.y, False, dtype=bool)\n",
    "            train_mask[idx[:num_train]] = True\n",
    "            test_mask = torch.full_like(g.y, False, dtype=bool)\n",
    "            test_mask[idx[num_train:]] = True\n",
    "            g.train_mask = train_mask\n",
    "            g.test_mask = test_mask\n",
    "\n",
    "    def _set_masks_(self,train_ratio=0.7):\n",
    "        \"\"\"\n",
    "        Assegna le maschere per i nodi associati al training set e al test set,\n",
    "        bilanciandole rispetto alle classi.\n",
    "\n",
    "        Args:\n",
    "            train_ratio (float): Frazione dei nodi da incorporare nel training set (0 < train_ratio < 1).\n",
    "        \"\"\"\n",
    "        for g in self.data:\n",
    "            num_nodes = g.x.shape[0]  # Numero totale di nodi\n",
    "\n",
    "            # Creazione delle maschere inizializzate a False\n",
    "            train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "            test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "            # Trova le classi presenti nei dati\n",
    "            classes = torch.unique(g.y)  # `g.y` contiene le etichette delle classi\n",
    "\n",
    "            for cls in classes:\n",
    "                # Indici dei nodi appartenenti alla classe corrente\n",
    "                class_indices = torch.nonzero(g.y == cls, as_tuple=True)[0]\n",
    "\n",
    "                # Mescola casualmente gli indici di questa classe\n",
    "                shuffled_indices = class_indices[torch.randperm(len(class_indices))]\n",
    "\n",
    "                # Numero di nodi da assegnare al training set per questa classe\n",
    "                num_train = int(len(class_indices) * train_ratio)\n",
    "\n",
    "                # Assegna i nodi ai set di training e test\n",
    "                train_mask[shuffled_indices[:num_train]] = True\n",
    "                test_mask[shuffled_indices[num_train:]] = True\n",
    "\n",
    "            # Assegna le maschere al grafo\n",
    "            g.train_mask = train_mask\n",
    "            g.test_mask = test_mask\n",
    "        \n",
    "    def get_masks(self,g):\n",
    "        '''\n",
    "        Restituisci le maschere per i nodi associati al training set e al test set\n",
    "        Args:\n",
    "            g (int): index of the graph in data list\n",
    "        Returns:\n",
    "            masks (tuple(Tensor,Tensor)): tupla contenente le maschere per esempi del train e test set\n",
    "        '''\n",
    "        G = self.data[g]\n",
    "        return G.train_mask,G.test_mask\n",
    "\n",
    "    def get_graph_info(self,idx):\n",
    "        '''\n",
    "        Restituisce informazioni relative al grafo in formato pytorch_geometric\n",
    "        Args:\n",
    "            G (Data): un grafo formato pythorch_geometric\n",
    "        '''\n",
    "        print(f'Number of nodes: {self.data[idx].num_nodes}') #Number of nodes in the graph\n",
    "        print(f'Number of edges: {self.data[idx].num_edges}') #Number of edges in the graph\n",
    "        print(f'Average node degree: {self.data[idx].num_edges / self.data[idx].num_nodes:.2f}') # Average number of nodes in the graph\n",
    "        print(f'Contains isolated nodes: {self.data[idx].has_isolated_nodes()}') #Does the graph contains nodes that are not connected\n",
    "        print(f'Contains self-loops: {self.data[idx].has_self_loops()}') #Does the graph contains nodes that are linked to themselves\n",
    "        print(f'Is undirected: {self.data[idx].is_undirected()}') #Is the graph an undirected graph\n",
    "\n",
    "    def get_data(self):\n",
    "        '''\n",
    "        Restituisce i grafi formato pytorch_geometric.\n",
    "        Returns:\n",
    "            _ Data: grafo\n",
    "        '''\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe ausiliaria per il training e l'evaluation del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,model,data,criterion,optimizer,metrics):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def train(self,num_epocs):\n",
    "        self.optimizer.zero_grad()\n",
    "        for epoc in range(num_epocs):\n",
    "            print(f'---- EPOCH {epoc} ----')\n",
    "            train_total_loss = 0    \n",
    "            for g in self.data:\n",
    "                train_loader = NeighborLoader(g,input_nodes=g.train_mask,num_neighbors=[8],batch_size=16,directed=False)\n",
    "                c = 0\n",
    "                tmp = 0\n",
    "                for batch in train_loader:\n",
    "                    loss= self._train_step_(batch)\n",
    "                    print(loss)\n",
    "                    tmp+=loss\n",
    "                    c+=1\n",
    "                train_total_loss += tmp / c\n",
    "                if (epoc+1) % 2 == 0:\n",
    "                    test_loader = NeighborLoader(g,input_nodes=g.test_mask,num_neighbors=[8],batch_size=16,directed=False)\n",
    "                    eval_total_loss = 0\n",
    "                    eval_metric_total = 0\n",
    "                    c = 0\n",
    "                    for batch in test_loader:\n",
    "                        loss,metric = self._evaluation_step_(batch)\n",
    "                        eval_total_loss += loss\n",
    "                        eval_metric_total += metric\n",
    "                        c+=1\n",
    "                    print(\"----- Evaluation -----\")\n",
    "                    eval_metric_total=eval_metric_total/c\n",
    "                    eval_total_loss = eval_total_loss/c\n",
    "                    print(f'{self.metrics}: {eval_metric_total}')\n",
    "                    print(f'loss {eval_total_loss}')\n",
    "\n",
    "            train_total_loss = train_total_loss / len(self.data)\n",
    "            print(f'Epoc {epoc} mean loss {train_total_loss}')\n",
    "\n",
    "    def _train_step_(self,batch):\n",
    "        self.model.train()\n",
    "        out = self.model(batch.x, batch.edge_index,batch.Weight)\n",
    "        loss = self.criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "    \n",
    "    def _evaluation_step_(self,batch):\n",
    "        self.model.eval()\n",
    "        out= self.model(batch.x, batch.edge_index)\n",
    "        predictions = torch.argmax(out[batch.test_mask], dim=1)\n",
    "        loss = self.criterion(out[batch.test_mask],batch.y[batch.test_mask])\n",
    "        metric = groundtruth_metrics(predictions, batch.y[batch.test_mask], metrics=self.metrics)\n",
    "        return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(G):\n",
    "    nodes = G.num_nodes\n",
    "    A = torch.zeros((nodes,nodes))\n",
    "    source_nodes, target_nodes = G.edge_index\n",
    "    A[source_nodes, target_nodes] = 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'preferential attachment net.json','mixed net.json', 'small world net.json','advanced mixed.json'\n",
    "GC = DatasetCreator(['advanced mixed.json'],['Score','Likes','Shares','Comments','Visuals','Dislikes'],['Interactions'],'Misinformative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GCN(in_channels=GC.get_data()[0].num_features,hidden_channels=3,num_layers=2,out_channels=2,dropout=0.8,norm=\"layer\",act_first=True,aggr=\"mean\")\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)  # Initialize the Adam optimizer.\n",
    "optimizer.zero_grad() # Clear gradients.\n",
    "\n",
    "def train(data,model):\n",
    "    model.train()\n",
    "    out = model(data.x,data.edge_index,data.Weight)  # Perform a single forward pass\n",
    "    out = nn.LogSoftmax(dim=1)(out)\n",
    "    loss = criterion(out[data.train_mask],data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def evaluate(data,model):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index,data.Weight)\n",
    "    out = nn.LogSoftmax(dim=1)(out)\n",
    "    predictions = torch.argmax(out[data.test_mask], dim=1)\n",
    "    loss = criterion(out[data.test_mask],data.y[data.test_mask])\n",
    "    metric = groundtruth_metrics(predictions, data.y[data.test_mask], metrics=[\"f1_score\"])\n",
    "    return loss, metric\n",
    "\n",
    "gs = GC.get_data()\n",
    "\n",
    "k = 0\n",
    "for i in range(5):\n",
    "    print(f'---EPOCH {i}----')\n",
    "    for g in gs:\n",
    "        train_loader = NeighborLoader(g,input_nodes=g.train_mask,num_neighbors=[8],batch_size=16,directed=False)\n",
    "        graph_avg_loss = 0\n",
    "        c=0\n",
    "        for batch in train_loader:\n",
    "            loss= train(batch,model)\n",
    "            graph_avg_loss += loss\n",
    "            c+=1\n",
    "        graph_avg_loss = graph_avg_loss/c\n",
    "        print(graph_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC = DatasetCreator(['advanced mixed test.json'],['Score','Likes','Shares','Comments','Visuals','Dislikes'],['Interactions'],'Misinformative')\n",
    "\n",
    "def draw_graph_with_label(G1,G2):\n",
    "        '''\n",
    "        Disegna il grafo originale e quello predetto con etichette.\n",
    "        Args:\n",
    "            G (Graph): un grafo\n",
    "        '''\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        i=0\n",
    "        pos = nx.spring_layout(G1)\n",
    "        for G in [G1,G2]:\n",
    "            labels = {}\n",
    "            for node, data in G.nodes(data=True):\n",
    "                labels.update({node:data[\"y\"]})\n",
    "            nx.draw(G1,pos,ax=axes[i],with_labels=False)\n",
    "            nx.draw_networkx_labels(G, pos,ax=axes[i], labels=labels, font_size=12, font_color='black')\n",
    "            tmp = \"original\" if i == 0 else \"predicted\"\n",
    "            axes[i].set_title(tmp)\n",
    "            i+=1\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def evaluate(data,model):\n",
    "    model.eval()\n",
    "    \n",
    "    out = model(data.x, data.edge_index,data.Weight)\n",
    "    out = nn.LogSoftmax(dim=1)(out)\n",
    "    predictions = torch.argmax(out, dim=1)\n",
    "    loss = criterion(out,data.y)\n",
    "    metric = groundtruth_metrics(predictions, data.y, metrics=[\"f1_score\"])\n",
    "\n",
    "    original = to_networkx(data,node_attrs= ['y'],to_undirected=True)\n",
    "    tmp = copy.copy(data)\n",
    "    tmp.y = predictions\n",
    "    predicted = to_networkx(tmp,node_attrs= ['y'],to_undirected=True)\n",
    "    draw_graph_with_label(original,predicted)\n",
    "    return loss, metric\n",
    "\n",
    "\n",
    "gs = GC.get_data()\n",
    "for g in gs:\n",
    "    test_loader = NeighborLoader(g,input_nodes=g.test_mask,num_neighbors=[8],batch_size=16,directed=False)\n",
    "    graph_avg_loss = 0\n",
    "    c=0\n",
    "    for batch in test_loader:\n",
    "        c+=1\n",
    "        evaluations = evaluate(batch,model)\n",
    "        graph_avg_loss += evaluations[0]\n",
    "    graph_avg_loss = graph_avg_loss / c\n",
    "    print(graph_avg_loss)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sma-prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
